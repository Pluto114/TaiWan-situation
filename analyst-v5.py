import json
import os
import requests
import feedparser
import datetime
from datetime import datetime, timezone
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# --- é…ç½®åŒº ---
DEEPSEEK_API_KEY = os.environ.get('DEEPSEEK_API_KEY')
NEWS_API_KEY = os.environ.get('NEWS_API_KEY')

DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"
NEWS_API_URL = "https://newsapi.org/v2/everything"
INDICATORS_FILE = "indicators.json"
SCORES_FILE = "scores-v3.json"

DECAY_FACTOR = 0.75
WEIGHT_FLOOR = 1

# --- 1. ç½‘ç»œè¯·æ±‚åŸºç¡€ ---

def create_retry_session():
    session = requests.Session()
    retry_strategy = Retry(
        total=3, status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET"], backoff_factor=1
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    return session

# --- 2. æ•°æ®èŽ·å–æ¨¡å— (è¿”å›žç»“æž„åŒ–æ•°æ®) ---

# A. å›½é™…/å•†ä¸šæ–°é—» (NewsAPI)
def fetch_newsapi_data(query, api_key, session):
    print(f"ðŸŒ æ­£åœ¨è°ƒç”¨ NewsAPI èŽ·å–: {query}...")
    headers = {"X-Api-Key": api_key}
    params = {
        "q": query, "language": "zh", "pageSize": 10,
        "sortBy": "publishedAt", 
        "searchIn": "title,description"
    }
    
    result = {"text": "", "articles": []}
    
    try:
        response = session.get(NEWS_API_URL, headers=headers, params=params, timeout=10)
        if response.status_code != 200: return result
        data = response.json()
        if data.get('totalResults', 0) == 0: return result
        
        summary = ""
        for article in data['articles'][:5]:
            title = article['title']
            date_str = article['publishedAt'][:10]
            source = article['source']['name']
            url = article['url']
            
            summary += f"- [NewsAPI] {title} ({date_str})\n"
            result["articles"].append({
                "title": title,
                "source": f"NewsAPI / {source}",
                "date": date_str,
                "url": url
            })
            
        result["text"] = summary
        return result
    except Exception as e:
        print(f"âš ï¸ NewsAPI è°ƒç”¨éƒ¨åˆ†å¤±è´¥: {e}")
        return result

# B. ä¸­å›½å®˜æ–¹ä¿¡æº (Google News RSS)
def fetch_official_sources():
    print("ðŸ‡¨ðŸ‡³ æ­£åœ¨ç›‘æŽ§ä¸­å›½å®˜æ–¹ä¿¡æº (é€šè¿‡ Google RSS)...")
    
    targets = [
        { "name": "å¤–äº¤éƒ¨/å›½é˜²éƒ¨", "query": "site:mfa.gov.cn OR site:mod.gov.cn" },
        { "name": "è§£æ”¾å†›æŠ¥/å†›ç½‘", "query": "site:81.cn OR site:chinamil.com.cn" },
        { "name": "æµ·äº‹å±€", "query": "site:msa.gov.cn AND (ç¦èˆª OR æ¼”ä¹  OR å®žå¼¹)" }
    ]
    
    result = {"text": "", "articles": []}
    all_text = ""
    
    for target in targets:
        encoded_query = requests.utils.quote(target['query'] + " when:2d")
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-CN&gl=CN&ceid=CN:zh-CN"
        
        try:
            feed = feedparser.parse(rss_url)
            if not feed.entries: continue
                
            all_text += f"\nã€{target['name']}ã€‘:\n"
            for entry in feed.entries[:3]:
                title = entry.title
                published = entry.published if 'published' in entry else "è¿‘æœŸ"
                link = entry.link if 'link' in entry else "#"
                
                # ç®€å•çš„æ—¥æœŸæ ¼å¼åŒ–
                try:
                    dt = datetime.strptime(published, "%a, %d %b %Y %H:%M:%S %Z")
                    date_str = dt.strftime("%Y-%m-%d")
                except:
                    date_str = published[:16]

                all_text += f"- {title} ({date_str})\n"
                result["articles"].append({
                    "title": title,
                    "source": f"å®˜æ–¹ä¿¡æº / {target['name']}",
                    "date": date_str,
                    "url": link
                })
                
        except Exception as e:
            print(f"âš ï¸ RSS èŽ·å–å¤±è´¥ ({target['name']}): {e}")
            
    result["text"] = all_text
    return result

# --- 3. ç»¼åˆæƒ…æŠ¥èŽ·å– ---

def get_combined_intelligence(category, news_api_query, news_api_key, session):
    final_text = ""
    all_articles = []
    
    # 1. NewsAPI
    news_res = fetch_newsapi_data(news_api_query, news_api_key, session)
    if news_res["text"]:
        final_text += "=== å›½é™…ä¸Žå•†ä¸šåª’ä½“ ===\n" + news_res["text"] + "\n"
        all_articles.extend(news_res["articles"])
    
    # 2. å®˜æ–¹ä¿¡æº (ä»…å†›äº‹/æ”¿æ²»)
    if category in ["å†›äº‹åŽå‹¤", "æ”¿æ²»èˆ†è®º"]:
        off_res = fetch_official_sources()
        if off_res["text"]:
            final_text += "=== å®˜æ–¹ä¿¡æº ===\n" + off_res["text"] + "\n"
            all_articles.extend(off_res["articles"])
            
    if not final_text: final_text = "æœªèŽ·å–åˆ°ç›¸å…³æ–°é—»ã€‚"
        
    return {"text": final_text, "articles": all_articles}

# --- 4. LLM åˆ†æž (ä¸å˜) ---

def get_triggered_indicators(category, news_text, indicators_list, api_key):
    category_indicators = [ind for ind in indicators_list if ind['category'] == category]
    if not category_indicators: return {"triggered_ids": [], "reasoning": "æ— æŒ‡æ ‡ã€‚"}

    system_prompt = f"""
    ä½ æ˜¯ä¸€åæ•é”çš„æƒ…æŠ¥åˆ†æžå¸ˆã€‚è¯·æ ¹æ®æä¾›çš„ã€æ··åˆæƒ…æŠ¥æºã€‘åˆ¤æ–­æ˜¯å¦**æ˜Žç¡®è§¦å‘**äº†é¢„è­¦æŒ‡æ ‡ã€‚
    
    **å…³é”®åˆ¤æ–­å‡†åˆ™ï¼š**
    1. **å®˜æ–¹ä¿¡æºæƒé‡æžé«˜ï¼š** å³ä½¿æ˜¯â€œä¾‹è¡Œè®°è€…ä¼šâ€ï¼Œå¦‚æžœå‘è¨€äººä½¿ç”¨äº†â€œæ€§è´¨æ¶åŠ£â€ã€â€œä¸¥é‡åŽæžœâ€ã€â€œæ˜Žç¡®äº¤ä»£â€ã€â€œååˆ¶â€ç­‰å¼ºç¡¬è¯æ±‡ï¼Œåº”è§†ä¸ºè§¦å‘â€œå¤–äº¤å¼ºç¡¬å£°æ˜Žâ€ç±»æŒ‡æ ‡ (å¦‚ POL-2)ã€‚
    2. **åŒºåˆ†çƒˆåº¦ï¼š** - ä¸€èˆ¬æŠ—è®® -> ä¸è§¦å‘
       - å¼ºç¡¬è­¦å‘Š/ä¸¥æ­£äº¤æ¶‰ -> è§¦å‘ä¸­ä½Žæƒé‡æŒ‡æ ‡ (POL-2)
       - æˆ˜äº‰å¨èƒ/æœ€åŽé€šç‰’ -> è§¦å‘é«˜æƒé‡æŒ‡æ ‡ (POL-1)
    3. **å®å¯è¯¯æŠ¥ä¸å¯æ¼æŠ¥ï¼š** å¯¹äºŽå®˜æ–¹çš„å¼‚å¸¸è¡¨æ€ï¼Œä¿æŒè¾ƒé«˜çš„æ•æ„Ÿåº¦ã€‚
    
    è¯·è¿”å›ž JSON: {{ "triggered_ids": ["ID1"], "reasoning": "ç®€çŸ­åˆ†æž..." }}
    """
    user_prompt = f"""
    **ã€é¢„è­¦æŒ‡æ ‡ ({category})ã€‘**
    {json.dumps(category_indicators, indent=2, ensure_ascii=False)}
    **ã€æ··åˆæƒ…æŠ¥æºã€‘**
    "{news_text}"
    """
    headers = { "Content-Type": "application/json", "Authorization": f"Bearer {api_key}" }
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
        "response_format": {"type": "json_object"}
    }
    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, data=json.dumps(payload), timeout=45)
        return json.loads(response.json()['choices'][0]['message']['content'])
    except Exception as e:
        print(f"âŒ LLM åˆ†æžå¤±è´¥: {e}")
        return {"triggered_ids": [], "reasoning": f"åˆ†æžå‡ºé”™: {e}"}

# --- 5. ä¸»ç¨‹åº ---

def main():
    if not DEEPSEEK_API_KEY or not NEWS_API_KEY:
        print("âŒ é”™è¯¯: ç¼ºå°‘ API å¯†é’¥ã€‚")
        exit(1)

    try:
        with open(INDICATORS_FILE, 'r', encoding='utf-8') as f:
            all_indicators_master = {ind['id']: ind for ind in json.load(f)}
    except:
        print(f"âŒ æ— æ³•åŠ è½½ {INDICATORS_FILE}")
        exit(1)

    try:
        with open(SCORES_FILE, 'r', encoding='utf-8') as f:
            yesterday_state = json.load(f).get('active_indicators', {})
    except:
        yesterday_state = {}

    session = create_retry_session()
    queries = {
        "ç»æµŽé‡‘èž": '(å°æ¹¾ OR ä¸­å›½) AND (ç»æµŽ OR è´¸æ˜“ OR åˆ¶è£ OR ä¾›åº”é“¾ OR èŠ¯ç‰‡)',
        "å†›äº‹åŽå‹¤": '(å°æ¹¾ OR ä¸­å›½) AND (å†›äº‹ OR æ¼”ä¹  OR è§£æ”¾å†› OR èˆªæ¯ OR ç¦èˆª)',
        "æ”¿æ²»èˆ†è®º": '(å°æ¹¾ OR ä¸­å›½) AND (å¤–äº¤ OR æ”¿æ²» OR è­¦å‘Š OR æ’¤ä¾¨)',
        "åœ¨åœ°ä½“æ„Ÿ(åŽ¦é—¨)": 'åŽ¦é—¨ AND (é˜²ç©º OR æ¼”ä¹  OR äº¤é€šç®¡åˆ¶)'
    }

    print("--- å¼€å§‹å¤šæºæƒ…æŠ¥é‡‡é›†ä¸Žåˆ†æž (V5.1) ---")
    
    results = {}
    news_sources = {} # ç”¨äºŽä¿å­˜æ–°é—»æº
    
    for category in ["ç»æµŽé‡‘èž", "å†›äº‹åŽå‹¤", "æ”¿æ²»èˆ†è®º", "åœ¨åœ°ä½“æ„Ÿ(åŽ¦é—¨)"]:
        key_map = {"ç»æµŽé‡‘èž": "econ", "å†›äº‹åŽå‹¤": "mil", "æ”¿æ²»èˆ†è®º": "pol", "åœ¨åœ°ä½“æ„Ÿ(åŽ¦é—¨)": "local"}
        key = key_map[category]
        
        # èŽ·å–æƒ…æŠ¥ (åŒ…å«æ–‡æœ¬å’Œæºåˆ—è¡¨)
        if category == "åœ¨åœ°ä½“æ„Ÿ(åŽ¦é—¨)":
            intel = {"text": "åŽ¦é—¨æœ¬åœ°å±…æ°‘åé¦ˆï¼šæœ¬å‘¨é˜²ç©ºè­¦æŠ¥æµ‹è¯•æ˜¯å¹´åº¦ä¾‹è¡Œæµ‹è¯•ï¼Œè¶…å¸‚ç‰©èµ„ä¾›åº”å……è¶³ï¼Œæœªè§æŠ¢è´­ï¼Œç¤¾ä¼šç§©åºæ­£å¸¸ã€‚", "articles": []}
        else:
            intel = get_combined_intelligence(category, queries[category], NEWS_API_KEY, session)
            
        # ä¿å­˜æ–°é—»æº
        news_sources[key] = intel["articles"]
        
        # LLM åˆ†æž
        results[key] = get_triggered_indicators(category, intel["text"], list(all_indicators_master.values()), DEEPSEEK_API_KEY)

    # --- çŠ¶æ€è®¡ç®— ---
    today_triggered_ids = set()
    for res in results.values():
        today_triggered_ids.update(res.get('triggered_ids', []))
    
    today_state = {}
    today_str = str(datetime.now(timezone.utc).date())

    for ind_id, data in yesterday_state.items():
        if ind_id not in all_indicators_master: continue
        base_weight = all_indicators_master[ind_id]['weight']
        if ind_id in today_triggered_ids:
            today_state[ind_id] = { "base_weight": base_weight, "current_weight": base_weight, "triggered_on": today_str }
        else:
            new_weight = data['current_weight'] * DECAY_FACTOR
            if new_weight >= WEIGHT_FLOOR:
                today_state[ind_id] = { "base_weight": base_weight, "current_weight": new_weight, "triggered_on": data['triggered_on'] }

    for ind_id in today_triggered_ids:
        if ind_id not in today_state and ind_id in all_indicators_master:
            base_weight = all_indicators_master[ind_id]['weight']
            today_state[ind_id] = { "base_weight": base_weight, "current_weight": base_weight, "triggered_on": today_str }

    total_possible = sum(i['weight'] for i in all_indicators_master.values())
    current_total = sum(i['current_weight'] for i in today_state.values())
    score = (current_total / total_possible) * 100 if total_possible > 0 else 0

    final_data = {
        "score": round(score),
        "total_indicators_possible": len(all_indicators_master),
        "active_indicators_count": len(today_state),
        "active_indicators": today_state,
        "category_reasoning": { k: v['reasoning'] for k, v in results.items() },
        "news_sources": news_sources, # <-- æ–°å¢žå­—æ®µ
        "last_updated": datetime.now(timezone.utc).isoformat()
    }
    
    with open(SCORES_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, indent=4, ensure_ascii=False)
    
    print(f"âœ… åˆ†æžå®Œæˆã€‚æ€»åˆ†: {round(score)}")

if __name__ == "__main__":
    main()

